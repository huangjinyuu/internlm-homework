# 体验 OpenCompass 

## 1. 配环境

```
# 新的虚拟环境
conda create -n opencompass python=3.10
conda activate opencompass

# 下载源码，安装opencompass本体及其相关依赖
cd /root
git clone -b 0.3.3 https://github.com/open-compass/opencompass
cd opencompass
pip install -e .
pip install -r requirements.txt
pip install huggingface_hub==0.25.2

# 安装pytorch
conda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=12.1 -c pytorch -c nvidia -y

# 其他依赖
apt-get update
apt-get install cmake
pip install protobuf==4.25.3
pip install huggingface-hub==0.23.2
```

## 2. 通过API测评

### 2.1 准备数据和配置文件

模型的配置文件：

```
import os
from opencompass.models import OpenAISDK


internlm_url = 'https://internlm-chat.intern-ai.org.cn/puyu/api/v1/' # 你前面获得的 api 服务地址
internlm_api_key = os.getenv('INTERNLM_API_KEY')

models = [
    dict(
        # abbr='internlm2.5-latest',
        type=OpenAISDK,
        path='internlm2.5-latest', # 请求服务时的 model name
        # 换成自己申请的APIkey
        key=internlm_api_key, # API key
        openai_api_base=internlm_url, # 服务地址
        rpm_verbose=True, # 是否打印请求速率
        query_per_second=0.16, # 服务请求速率
        max_out_len=1024, # 最大输出长度
        max_seq_len=4096, # 最大输入长度
        temperature=0.01, # 生成温度
        batch_size=1, # 批处理大小
        retry=3, # 重试次数
    )
]
```

数据集的配置：

```
# opencompass/configs/datasets/demo/demo_cmmlu_chat_gen.py

from mmengine import read_base
with read_base():
    # 导入完整的CMMLU数据集配置
    from ..cmmlu.cmmlu_gen_c13365 import cmmlu_datasets

# 修改每个数据集的配置
for d in cmmlu_datasets:
    # 给数据集名称添加"demo_"前缀
    d['abbr'] = 'demo_' + d['abbr']
    
    # 设置测试范围为[0:1],表示只取第一个样本
    d['reader_cfg']['test_range'] = '[0:1]'
```

准备好数据和模型的配置文件，就可以运行Opencompass了

### 2.2 OpenCompass！启动！
启动评测：

![image](https://github.com/user-attachments/assets/4b8da074-6bb2-4dac-87b3-9dbab9f779b1)

运行结果：

![image](https://github.com/user-attachments/assets/5e8fc4f4-90e1-4d82-bdd1-fd77b541a961)


## 3. 测评本地LLM

### 3.1 准备数据和配置文件

准备好数据和模型的配置文件，就可以运行Opencompass了

### 3.2 OpenCompass！启动！

![image](https://github.com/user-attachments/assets/5eb5fbb7-f6a1-4e04-8423-836d8012a0d7)


## 附录1：报错与解决

1. 初始情况：
```bash
# 尝试运行 OpenCompass
python run.py --models puyu_api.py --datasets demo_cmmlu_chat_gen.py --debug

# 报错：找不到 rouge 模块
ModuleNotFoundError: No module named 'rouge'
```

2. 检查环境：
```bash
# 查看 rouge 包状态
pip show rouge
# 显示已安装在 /root/.conda/envs/opencompass/lib/python3.10/site-packages

# 尝试导入验证
python
>>> import rouge  # 失败了！
ModuleNotFoundError: No module named 'rouge'
```

3. 解决过程：
```bash
# 先卸载
pip uninstall rouge
Successfully uninstalled rouge-1.0.1

# 重新安装
pip install rouge
Using cached https://pypi.tuna.tsinghua.edu.cn/packages/...rouge-1.0.1-py3-none-any.whl
Successfully installed rouge-1.0.1

# 再次验证
python
>>> import rouge      # 成功了！
>>> from rouge import Rouge  # 也成功了！
```

有趣的发现：
1. 包管理器(pip)显示包已安装，但 Python 无法导入
2. 重装时用的还是缓存的相同包文件
3. 但重装后问题就解决了

可能的原因：
- 首次安装可能没完成全部安装步骤
- 或者文件权限/路径出了问题
- 重装过程虽然用了相同的包文件，但执行了完整的安装流程，修复了这些问题

教训：
1. pip show 显示包存在不代表包能正常使用
2. 有时候"重装"虽然看起来是多余的操作，但确实能解决问题
3. 包的安装不仅是文件复制，还包括其他配置步骤

## 附录2：ppl 和 gen

通过一个具体的例子解释 `ppl`、`gen` 的区别。假设有一道选择题:

问题: 下列哪个是哺乳动物?
A. 鲨鱼
B. 海豚
C. 金鱼
D. 鳄鱼

让我们看看不同方法如何处理:

1. **PPL (困惑度)方法**:
```
# 将分别计算这4个序列的困惑度:

序列1: "问题:下列哪个是哺乳动物? 答案是鲨鱼"
序列2: "问题:下列哪个是哺乳动物? 答案是海豚" 
序列3: "问题:下列哪个是哺乳动物? 答案是金鱼"
序列4: "问题:下列哪个是哺乳动物? 答案是鳄鱼"

假设计算得到的困惑度分别是:
序列1: 8.2
序列2: 3.1  (最低,说明最可能)
序列3: 7.8
序列4: 6.5

因此选择B(海豚)作为答案
```

2. **GEN (生成)方法**:
```
输入: "问题:下列哪个是哺乳动物?"

模型可能的输出:
"让我们来分析一下:
1. 鲨鱼是软骨鱼类,不是哺乳动物
2. 海豚虽然生活在水中,但它们是哺乳动物,需要用肺呼吸
3. 金鱼是鱼类,不是哺乳动物
4. 鳄鱼是爬行动物,不是哺乳动物

所以答案是B. 海豚"

需要后处理提取出"B"或"海豚"作为最终答案
```


主要区别:
- PPL需要多次计算,但结果较稳定
- GEN只需计算一次,但需要复杂的后处理

这就是为什么:
1. 基础模型的单选题主要用PPL
2. 其他题型用GEN
3. 对话模型全部用GEN(因为API限制)
