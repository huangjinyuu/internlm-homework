# MindSearch深度解析及实践 

## CPU部署：调用LLM API

### 配环境


新建一个目录用于存放 MindSearch 的相关代码，并把 MindSearch 仓库 clone 下来。

```bash
mkdir -p /root/mindsearch
cd /root/mindsearch
git clone https://github.com/InternLM/MindSearch.git
cd MindSearch && git checkout b832275 && cd ..
```

我们创建一个 conda 环境来安装相关依赖。

```bash
# 创建环境
conda create -n mindsearch python=3.10 -y
# 激活环境
conda activate mindsearch
# 安装依赖
pip install -r /root/mindsearch/MindSearch/requirements.txt
```

### 启动 MindSearch




## GPU部署：本地推理LLM


## how it works?

### 1. 核心架构组件

MindSearch采用多代理(Multi-Agent)框架，主要包含两个核心组件：
- 采用WebPlanner和WebSearcher两类代理协同工作
- WebPlanner负责高层规划，WebSearcher执行具体搜索
- 使用有向无环图(DAG)建模问题求解过程
- 支持子任务的并行执行

#### 1.1 WebPlanner
- 功能：高级规划器，负责任务分解和推理编排
- 实现要点：
  - 将复杂问题建模为有向无环图(DAG)结构
  - 使用代码生成方式构建推理图
  - 支持并行任务分发
  - 通过图构建动态管理上下文

#### 1.2 WebSearcher
- 功能：执行具体的网络搜索和信息提取
- 实现要点：
  - 采用分层检索策略(Hierarchical Retrieval)
  - 包含查询重写、内容聚合、页面选择等步骤
  - 支持多搜索引擎API(Google, Bing, DuckDuckGo)

### 2. 关键工作流程

#### 2.1 查询分解与规划
1. WebPlanner接收用户查询
2. 将查询分解为原子级子问题
3. 构建DAG表示问题求解路径
4. 生成Python代码实现图的动态构建

#### 2.2 并行信息检索
1. WebSearcher接收子问题
2. 生成多个相似查询扩展搜索范围、查询重写
3. 调用搜索API获取初步结果
4. 基于URL合并搜索结果
5. 选择最相关页面深入分析

#### 2.3 上下文管理
1. 在代理间显式传递上下文状态
2. 使用图边关系处理上下文依赖
3. 为每个WebSearcher添加父节点和根节点响应前缀
4. 保持子任务焦点的同时维护整体上下文

### 3. 其他细节

1. **分层检索是什么**？
- 想象成"三重过滤"系统：
  - 第一层(粗筛)：快速浏览搜索结果的标题和简介，筛选出可能相关的页面
  - 第二层(精筛)：对筛选出的页面进行更详细的分析，确定真正相关的内容
  - 第三层(深度分析)：只对最相关的页面进行完整内容的下载和深入分析

![image](https://github.com/user-attachments/assets/8ffcf952-9bc2-4a0a-9ee9-9e3dd788dab6)


举个例子：如果你搜索"苹果公司最新iPhone"
- 第一层可能返回100个结果
- 第二层筛选出20个相关度高的页面
- 第三层可能只分析5个最权威的源网页

2. **基于URL合并是什么**？
- 目的：去除重复内容，整合相似信息
- 工作方式：
  ```
  例如搜索返回这些URL：
  - news.com/iphone15-review
  - news.com/iphone15-review?source=home
  - othernews.com/iphone15-review
  
  系统会：
  1. 识别出前两个URL指向同一内容
  2. 只保留一个版本
  3. 合并不同网站的补充信息
  ```

3. **上下文管理是怎么工作的**？
来看一个具体例子：

![image](https://github.com/user-attachments/assets/c56db5ef-3fef-4c28-9063-b4b3c6f322b2)

在这个例子中：

1. 显式传递上下文：
   ```
   原始问题: "分析iPhone 15的优缺点"
   子任务A: "总体评价" + 原始问题
   子任务B: "优点分析" + 原始问题
   子任务C: "缺点分析" + 原始问题
   ```
   每个子任务都知道自己在解决什么大问题

2. 图边关系处理：
   - B1(性能提升)知道自己是B(优点分析)的一部分
   - C1(价格)知道自己是C(缺点分析)的一部分
   
3. 父节点和根节点响应：
   ```
   当C2(续航)执行时，它知道：
   - 根节点是"iPhone 15分析"
   - 父节点是"缺点分析"
   - 自己的任务是"分析续航问题"
   ```

4. 保持焦点同时维护整体：
   - 每个小任务专注于自己的部分（如"分析续航"）
   - 但回答时会考虑整体上下文（这是在分析iPhone 15的缺点）
   - 避免答非所问或失去重点

这种设计让系统能够：
1. 准确理解每个子任务的目标
2. 保持回答的连贯性
3. 避免重复工作
4. 产生结构化的完整答案

这样的设计类似于人类写研究报告：
- 知道整体是什么（报告主题）
- 明确自己负责哪部分（具体章节）
- 理解和其他部分的关系（章节关联）
- 既能专注细节又不丢失整体视角

### 4. 后端文件逻辑

简单分析 `/MindSearch/mindsearch/app.py` 的逻辑。

**主要组件**：
- FastAPI作为Web框架
- EventSourceResponse用于流式响应
- janus.Queue用于异步/同步队列转换
- 支持CORS跨域请求

**配置参数**：
```python
def parse_arguments():
    parser.add_argument('--lang', default='cn')              # 语言设置
    parser.add_argument('--model_format', default='internlm_server') # 模型格式
    parser.add_argument('--search_engine', default='DuckDuckGoSearch') # 搜索引擎
```

用直观的方式解释当你输入一个问题后发生的事情：

1. **输入阶段**
当你输入一个问题，比如"分析iPhone 15的优缺点"：
```python
# 通过 /solve 接口接收你的问题
@app.post('/solve')
async def run(request: GenerationParams):
    inputs = request.inputs  # 这里接收到你的问题
    # 初始化核心处理引擎
    agent = init_agent(lang=args.lang, 
                      model_format=args.model_format,
                      search_engine=args.search_engine)
```

2. **处理阶段**
```python
# 开始处理你的问题
for response in agent.stream_chat(inputs):
    # agent.stream_chat 是核心处理过程，它会：
    # 1. 分解你的问题（比如拆分为"性能"、"相机"、"电池"等子问题）
    # 2. 对每个子问题进行网络搜索
    # 3. 分析搜索结果
    # 4. 整合信息形成答案
```

3. **实时反馈**
系统会实时返回处理进度：
```python
# 每当有新的进展，就会通过这个机制返回给你
response_json = json.dumps({
    'response': agent_return,  # 当前的处理结果
    'current_node': node_name  # 正在处理哪个部分
})
yield {'data': response_json}
```

---

MindSearch的核心魔法在 `agent.stream_chat(inputs)` 内部。

真正的核心在 `init_agent()` 创建的 agent 对象中，这才是 MindSearch 的"大脑"：

![image](https://github.com/user-attachments/assets/6690c223-e082-4ca4-a02b-4cb51b9adb6b)

MindSearch的核心流程是：

1. **WebPlanner大脑**
```python
# 比如你问："分析iPhone 15的优缺点"
WebPlanner会思考：
- "需要查什么？" -> 拆解成多个方面
- "如何查？" -> 设计搜索策略
- "查完后怎么整合？" -> 规划结果处理
```

2. **WebSearcher执行器**
```python
# WebPlanner规划后，WebSearcher负责：
- 并行执行多个搜索任务
- 对每个搜索结果进行筛选
- 提取有价值的信息
```

3. **信息整合**
```python
# 所有搜索完成后：
- 整合各个方面的信息
- 去除重复内容
- 组织成连贯的答案
```

我在看的这个文件是一个"调度员"：
- 它负责接收用户问题
- 启动处理流程
- 实时反馈结果
- 但真正的"智慧"在 Agent 内部

你可以理解为：
- 这个文件就像餐厅的服务员，负责接单和上菜
- 而 Agent 才是后厨的大厨，真正进行烹饪的地方

如果你想了解 MindSearch 最核心的部分，我们应该看 Agent 的代码，那里包含了：
1. WebPlanner 如何思考和规划
2. WebSearcher 如何搜索和处理信息
3. 整个系统如何协同工作

### 5. agent逻辑
文件在这里：
```
(mindsearch) root@intern-studio-50007388:~/mindsearch/MindSearch/mindsearch/agent# ls
init.py  mindsearch_agent.py  mindsearch_prompt.py  models.py
```

这些就是核心代码文件，让我解释一下每个文件的作用：

1. **mindsearch_agent.py** - 这是最核心的实现文件
```
这里包含了:
- WebPlanner的实现：如何分析问题、规划搜索
- WebSearcher的实现：如何执行搜索、处理结果
- 整个Agent的协调逻辑
```

2. **mindsearch_prompt.py** - 这是"大脑"的思维模式设计
```
这里定义了:
- 如何引导大模型思考
- 如何让它像人类专家一样分析问题
- 如何进行任务分解和规划
```

3. **models.py** - 这是数据结构定义
```
这里定义了:
- 系统中使用的各种数据类型
- 状态码
- 接口规范
```

4. **__init__.py** - 这是包的初始化文件
```
这里负责:
- 导出主要的类和函数
- 配置初始化
```

---




